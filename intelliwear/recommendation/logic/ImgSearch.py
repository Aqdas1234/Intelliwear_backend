# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10lcyc9Jt8JTnmsxgqmBHcSl2eDMaCUn5


from google.colab import drive
drive.mount('/content/drive', force_remount=True)
# drive.flush_and_unmount()
"""

import requests
from io import BytesIO

import os
from PIL import Image

import torch
import torch.nn as nn
import torchvision
from torchvision import transforms
import numpy as np
import faiss
import pickle


class SearchModel:
    def __init__(self, directory):
        self.indexPath = directory + '/index.pkl'
        self.mappingsPath = directory + '/mappings.pkl'
        self.modelPath = directory + '/model.pkl'
        self.vectorPath = directory + '/vectors.pkl'
        self.dim = 512

        self.transform = transforms.Compose([
          transforms.Resize((256 , 256)) ,
          transforms.ToTensor() ,
          transforms.Normalize(mean = [0.485 , 0.456 , 0.406] , std = [0.229 , 0.224 , 0.225])
        ])

        self.model = None
        self.index = None
        self.activation= {}
        self.idMappings = {}
        self.reverseIdMappings = {}
        self.idTovectors = {}

        if self.is_trained():
            print("Model is pretrained")
            # self.saveVectors()
            self.get_model()
            self.vectors = self.getSavedVectors()
            self.getRNN()
            self.setActivation()
        else:
            self.model = torchvision.models.resnet18(weights = "DEFAULT")
            # self.model.eval()
            index = faiss.IndexFlatL2(self.dim)
            index_with_ids = faiss.IndexIDMap(index)
            self.index = index_with_ids
            self.saveRNN()
            self.saveModel()
            self.setActivation()
            
    def getSavedVectors(self):
      with open(self.vectorPath, "rb") as f:
            self.idTovectors = pickle.load(f)
    def saveVectors(self):
      with open(self.vectorPath, "wb") as f:
            pickle.dump(self.idTovectors, f)

    def getRNN(self):
      with open(self.modelPath, "rb") as f:
            self.model = pickle.load(f)

    def saveRNN(self):
      with open(self.modelPath, "wb") as f:
            pickle.dump(self.model, f)

    def saveModel(self):
        with open(self.indexPath, "wb") as f:
            pickle.dump(self.index, f)

        with open(self.mappingsPath, "wb") as f:
            pickle.dump((self.idMappings, self.reverseIdMappings), f)

        with open(self.vectorPath, "wb") as f:
                    pickle.dump(self.idTovectors, f)
    def get_model(self):
        with open(self.indexPath, "rb") as f:
            self.index = pickle.load(f)

        with open(self.mappingsPath, "rb") as f:
            self.idMappings, self.reverseIdMappings = pickle.load(f)

    def get_activation(self,name):
        def hook(model , input , output):
              self.activation[name] = output.detach()
        return hook

    def setActivation(self):
        self.model.avgpool.register_forward_hook(self.get_activation("avgpool"))
        self.model.eval()

    def getVectors(self , path):

      with torch.no_grad():
        try:
            
            img = Image.open(BytesIO(requests.get(path).content)).convert("RGB")
            img = self.transform(img)
            out = self.model(img[None, ...])
            vec = self.activation["avgpool"].numpy().squeeze()[None, ...]
            return vec
        except Exception as e:
            #print(f"Error processing image {path}: {e}")
            return None

    def addToIndex(self, id , vec):
        self.idTovectors[id] = vec.reshape(self.dim)

        if self.idMappings:
            internal = max(self.idMappings.values()) + 1
        else:
            internal = 0

        self.idMappings[id] = internal
        self.reverseIdMappings[internal] = id

        vec = vec.reshape(1, self.dim)
        self.index.add_with_ids(vec, np.array([internal], dtype='int64'))

        self.saveModel()
        self.saveVectors()


    def deleteProduct(self,id):
        if id not in self.idMappings:
            print(f"[Warning] ID {id} not found in index.")
            return
        del self.idTovectors[id]
        internal = self.idMappings[id]
        self.index.remove_ids(np.array([internal], dtype='int64'))

        del self.idMappings[id]
        del self.reverseIdMappings[internal]
        self.saveModel()
        self.saveVectors()

    def is_trained(self):
        # import os
        return os.path.isfile(self.modelPath)

    def search(self, img , k=20):
        #img = Image.open(path)
        temp = img.resize((200,200))
        img = self.transform(img)
        out = self.model(img[None , ...])
        target = self.activation["avgpool"].numpy().squeeze()[None , ...]
        top = self.index.search(target, k)[1][0]
        ids = [self.reverseIdMappings[i] for i in top if i != -1]
        return ids

    def addProduct(self ,id , img):
      vec = self.getVectors(img)
      self.addToIndex(id , vec)

    def addBatchProducts(self, ids , images):
        with torch.no_grad():
          for i in range(len(ids)):
              # print(root+file)
              try:
                  img = Image.open(images[i])
                  img = self.transform(img)
                  out = self.model(img[None , ...])
                  vec = self.activation["avgpool"].numpy().squeeze()[None , ...]
                  self.addToIndex(ids[i] , vec)
              except:

                  continue
              if i % 100 == 0 and i != 0:
                  print(i , "done")

    def cleanIndex(self):
      valid_ids = list(self.idTovectors.keys())
      active_vectors = np.array([self.idTovectors[id_] for id_ in valid_ids])
      valid_ids = [self.idMappings[id_] for id_ in valid_ids]
      self.index = faiss.IndexFlatL2(active_vectors.shape[1])
      self.index = faiss.IndexIDMap(self.index)
      self.index.add_with_ids(active_vectors, np.array(valid_ids, dtype='int64'))

'''
path = "D:/intelliwear_backend/intelliwear/recommendation/imageSearchData"
m = SearchModel(path)
print(m.idMappings)
# res = m.search(root1+test[400],5)
# res1 = [root+j for j in res]
# res1.insert(0,root1+test[400])
# getImages(res1)
'''